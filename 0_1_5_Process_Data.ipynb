{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce6d46eb-38e9-46ac-80ad-7e9d92bc1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2db11b-6950-48db-a8ef-49a322b14554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "import copy\n",
    "\n",
    "# adapt the custom Scikit-learn transformer(in transformers) that transforms categorical features to numerical ones to one that can be used here\n",
    "class CatNumTransformer(TransformerMixin):\n",
    "    def __init__(self, cols, max_classes):\n",
    "        self.cols = cols\n",
    "        self.cat_mapping = {}\n",
    "        self.max_classes = max_classes\n",
    "\n",
    "    def fit(self, X, y=None, *args, **kwargs):\n",
    "        # map each category to a numeric value; the numeric value is the maximum age found for that\n",
    "        # category\n",
    "        for col in self.cols:\n",
    "            categories = X[col].unique()\n",
    "            # create category-to-max age mapping\n",
    "            mapping = dict(X.groupby(col).age_in_months.max())\n",
    "            self.cat_mapping[col] = mapping\n",
    "                   \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, *args, **kwargs):\n",
    "        # replace categories by their assigned max age value\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].apply(lambda x: self.cat_mapping[col][x])\n",
    "        return X\n",
    "    \n",
    "    def run(self, X):\n",
    "        self.fit(X)\n",
    "        self.transform(X)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea37b805-b623-44d1-b97d-60826a8d1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to prepare the data for training and testing. The result is a dictionary containing:\n",
    "    # 1: The training and testing data, without targets\n",
    "    # 2: The training and testing targets\n",
    "    # 3: The implementation set data\n",
    "    # 4: The implementation set IMO numbers\n",
    "    # 5: The cross-validation folds\n",
    "def data_prep(df, K, predictors, response_col, fix_random_state=None):\n",
    "    # filter out ships that are younger than 84 years\n",
    "    df = df[df.age_in_months >= 84]\n",
    "    # Split into data for model development and data for model implementation\n",
    "    data_in_imp = df[df.implem_set == 1] #TODO - nothing currently in implementation set?? What to do???\n",
    "    data_in_dev = df[df.implem_set == 0]\n",
    "    # extract the IMO numbers from the implementation set\n",
    "    implem_ref = data_in_imp.imo_pseudo #IMO\n",
    "    # Select targets from development data\n",
    "    targets = data_in_dev[response_col].reset_index(drop=True)\n",
    "    # Select predictors from development data  and implementation set\n",
    "    data_in_dev = data_in_dev[predictors].reset_index(drop=True)\n",
    "    data_in_imp = data_in_imp[predictors]\n",
    "    # create K-fold cross validation folds\n",
    "    splitter = StratifiedKFold(n_splits=K, shuffle=True, random_state=fix_random_state)\n",
    "    folds = splitter.split(data_in_dev, targets)\n",
    "    folds = [[a,b] for a,b in folds]\n",
    "    # create result dictionary\n",
    "    data_prep_dict = {}\n",
    "    data_prep_dict['X'] = data_in_dev\n",
    "    data_prep_dict['Y'] = targets\n",
    "    data_prep_dict['implem_set'] = data_in_imp\n",
    "    data_prep_dict['implem_ref'] = implem_ref\n",
    "    data_prep_dict['folds'] = folds\n",
    "    \n",
    "    return data_prep_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c6fab3-8fbe-4c1b-bf52-6afd6f7978f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of predictors to use\n",
    "predictors = [\"GSS_Type\",\n",
    "              \"GSS_Propulsion\",\n",
    "              \"GSS_Main.engines..Model\",\n",
    "              \"GSS_Main.engines..Designer\",\n",
    "              \"GSS_Main.engines..Builder.code\",\n",
    "              \"GSS_Gross.tonnage\",\n",
    "              \"GSS_Deadweight\",\n",
    "              \"GSS_TEU\",\n",
    "              \"GSS_Insulated.capacity\",\n",
    "              \"GSS_Length.overall\",\n",
    "              \"GSS_Length.between.perpendiculars\",\n",
    "              \"GSS_Service.speed\",\n",
    "              \"GSS_Main.engines..Number.of.main.engines\",\n",
    "              \"GSS_Main.engines..Max..power\",\n",
    "              \"age_in_months\"]\n",
    "\n",
    "# specify which predictors need to be transformed from categorical to numerical as the oldest age of a ship in with that model/designer/builder\n",
    "cols_to_numeric = [\"GSS_Main.engines..Model\",\n",
    "                   \"GSS_Main.engines..Designer\",\n",
    "                   \"GSS_Main.engines..Builder.code\"]\n",
    "\n",
    "# specify which predictors need to be one-hot-encoded - in this case, I am using cat to numeric here too\n",
    "# HOW TO: pd.get_dummies(sloopschepen, columns=cols_to_encode).head() #  For one hot encoding - will avoid this for now, for amount of new columns created\n",
    "\n",
    "cols_to_encode = [\"GSS_Type\", \n",
    "                 \"GSS_Propulsion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757bb717-85e1-4df0-8329-3637159a5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Data\n",
    "sloopschepen =  pd.read_csv(\"sloopschepen_2016_2019.csv\")\n",
    "\n",
    "# convert columns to category that need to be transformed to numeric\n",
    "sloopschepen = sloopschepen.astype({cols_to_encode[0]: 'category',\n",
    "                                    cols_to_encode[1]: 'category'})\n",
    "\n",
    "# now convert those same columns to their numerics\n",
    "for column_convert in cols_to_encode:\n",
    "    sloopschepen[column_convert+\"_numeric\"] = sloopschepen[column_convert].cat.codes\n",
    "\n",
    "# Convert the columns that are aged by the categories in that column\n",
    "sloopschepen = CatNumTransformer(cols=cols_to_numeric, max_classes=2).run(sloopschepen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2818dba6-278f-4029-bbdf-897b9de5e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors after coversions\n",
    "predictors_final = [\"GSS_Type_numeric\",\n",
    "                  \"GSS_Propulsion_numeric\",\n",
    "                  \"GSS_Main.engines..Model\",\n",
    "                  \"GSS_Main.engines..Designer\",\n",
    "                  \"GSS_Main.engines..Builder.code\",\n",
    "                  \"GSS_Gross.tonnage\",\n",
    "                  \"GSS_Deadweight\",\n",
    "                  \"GSS_TEU\",\n",
    "                  \"GSS_Insulated.capacity\",\n",
    "                  \"GSS_Length.overall\",\n",
    "                  \"GSS_Length.between.perpendiculars\",\n",
    "                  \"GSS_Service.speed\",\n",
    "                  \"GSS_Main.engines..Number.of.main.engines\",\n",
    "                  \"GSS_Main.engines..Max..power\",\n",
    "                  \"age_in_months\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6b64b4-d75a-444a-9de3-0da39f7b484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# set parameters\n",
    "K = 5\n",
    "state = 0\n",
    "\n",
    "# prepare the data \n",
    "df = data_prep(df=sloopschepen,\n",
    "               K=K,\n",
    "               predictors=predictors_final,\n",
    "               response_col=\"dismantled\",\n",
    "               fix_random_state=state)\n",
    "# open a file, where you ant to store the data\n",
    "file = open('data_folds_7_11', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(df, file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# len(df['folds'][0][0])\n",
    "# df['X'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759515ef-4e44-4a98-9ec5-e30cd94c79a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open('data_folds_7_11', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "df = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d2f3de-576e-425c-909a-2ca527f144d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_fold = 0\n",
    "train_idxes = df['folds'][current_fold][0]\n",
    "test_idxes = df['folds'][current_fold][1]\n",
    "\n",
    "train_dataset_X = df['X'].loc[list(train_idxes), :]\n",
    "train_dataset_Y = df['Y'].loc[list(train_idxes)]\n",
    "\n",
    "test_dataset_X = df['X'].loc[list(test_idxes), :]\n",
    "test_dataset_Y = df['Y'].loc[list(test_idxes)]\n",
    "# train_dataset_X[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19a1fb-8d83-4ff3-af7f-f761e4c276c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfs_env",
   "language": "python",
   "name": "gfs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
